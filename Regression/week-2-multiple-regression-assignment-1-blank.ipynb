{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 2: Multiple Regression (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first notebook is to explore multiple regression and feature engineering with existing graphlab functions.\n",
    "\n",
    "In this notebook you will use data on house sales in King County to predict prices using multiple regression. You will:\n",
    "* Use SFrames to do some feature engineering\n",
    "* Use built-in graphlab functions to compute the regression weights (coefficients/parameters)\n",
    "* Given the regression weights, predictors and outcome write a function to compute the Residual Sum of Squares\n",
    "* Look at coefficients and interpret their meanings\n",
    "* Evaluate multiple models via RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;32m1451271469 : INFO:     (initialize_globals_from_environment:282): Setting configuration variable GRAPHLAB_FILEIO_ALTERNATIVE_SSL_CERT_FILE to /Users/doria/.graphlab/anaconda/lib/python2.7/site-packages/certifi/cacert.pem\n",
      "\u001b[0m\u001b[1;32m1451271469 : INFO:     (initialize_globals_from_environment:282): Setting configuration variable GRAPHLAB_FILEIO_ALTERNATIVE_SSL_CERT_DIR to \n",
      "\u001b[0mThis non-commercial license of GraphLab Create is assigned to owenzhang1990@gmail.com and will expire on October 31, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-18291 - Server binary: /Users/doria/.graphlab/anaconda/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1451271469.log\n",
      "[INFO] GraphLab Server Version: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and testing.\n",
    "We use seed=0 so that everyone running this notebook gets the same results.  In practice, you may set a random seed (or let GraphLab Create pick a random seed for you).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a multiple regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall we can use the following code to learn a multiple regression model predicting 'price' based on the following features:\n",
    "example_features = ['sqft_living', 'bedrooms', 'bathrooms'] on training data with the following code:\n",
    "\n",
    "(Aside: We set validation_set = None to ensure that the results are always the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 17384\n",
      "PROGRESS: Number of features          : 3\n",
      "PROGRESS: Number of unpacked features : 3\n",
      "PROGRESS: Number of coefficients    : 4\n",
      "PROGRESS: Starting Newton Method\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 2        | 1.049184     | 4146407.600631     | 258679.804477 |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "example_features = ['sqft_living', 'bedrooms', 'bathrooms']\n",
    "example_model = graphlab.linear_regression.create(train_data, target = 'price', features = example_features, \n",
    "                                                  validation_set = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the model we can extract the regression weights (coefficients) as an SFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------------+\n",
      "|     name    | index |     value      |\n",
      "+-------------+-------+----------------+\n",
      "| (intercept) |  None | 87910.0724924  |\n",
      "| sqft_living |  None | 315.403440552  |\n",
      "|   bedrooms  |  None | -65080.2155528 |\n",
      "|  bathrooms  |  None | 6944.02019265  |\n",
      "+-------------+-------+----------------+\n",
      "[4 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_weight_summary = example_model.get(\"coefficients\")\n",
    "print example_weight_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "In the gradient descent notebook we use numpy to do our regression. In this book we will use existing graphlab create functions to analyze multiple regressions. \n",
    "\n",
    "Recall that once a model is built we can use the .predict() function to find the predicted values for data we pass. For example using the example model above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271789.505878\n"
     ]
    }
   ],
   "source": [
    "example_predictions = example_model.predict(train_data)\n",
    "print example_predictions[0] # should be 271789.505878"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can make predictions given the model, let's write a function to compute the RSS of the model. Complete the function below to calculate RSS given the model, data, and the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_residual_sum_of_squares(model, data, outcome):\n",
    "    # First get the predictions\n",
    "    predications = model.predict(data)\n",
    "    # Then compute the residuals/errors\n",
    "    residuals = outcome - predications\n",
    "    # Then square and add them up\n",
    "    RSS = (residuals * residuals).sum()\n",
    "    return(RSS)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function by computing the RSS on TEST data for the example model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-aa721f0cfbc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrss_example_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_residual_sum_of_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mrss_example_train\u001b[0m \u001b[0;31m# should be 2.7376153833e+14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'example_model' is not defined"
     ]
    }
   ],
   "source": [
    "rss_example_train = get_residual_sum_of_squares(example_model, test_data, test_data['price'])\n",
    "print rss_example_train # should be 2.7376153833e+14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we often think of multiple regression as including multiple different features (e.g. # of bedrooms, squarefeet, and # of bathrooms) but we can also consider transformations of existing features e.g. the log of the squarefeet or even \"interaction\" features such as the product of bedrooms and bathrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the logarithm function to create a new feature. so first you should import it from the math library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create the following 4 new features as column in both TEST and TRAIN data:\n",
    "* bedrooms_squared = bedrooms\\*bedrooms\n",
    "* bed_bath_rooms = bedrooms\\*bathrooms\n",
    "* log_sqft_living = log(sqft_living)\n",
    "* lat_plus_long = lat + long \n",
    "As an example here's the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['bedrooms_squared'] = train_data['bedrooms'].apply(lambda x: x**2)\n",
    "test_data['bedrooms_squared'] = test_data['bedrooms'].apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the remaining 3 features in both TEST and TRAIN data\n",
    "train_data['bed_bath_rooms'] = train_data['bedrooms'] * train_data['bathrooms']\n",
    "test_data['bed_bath_rooms'] = test_data['bedrooms'] * test_data['bathrooms']\n",
    "train_data['log_sqft_living'] = train_data['sqft_living'].apply(lambda x: log(x))\n",
    "test_data['log_sqft_living'] = test_data['sqft_living'].apply(lambda x: log(x))\n",
    "train_data['lat_plus_long'] = train_data['lat'] + train_data['long']\n",
    "test_data['lat_plus_long'] = test_data['lat'] + test_data['long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this feature will mostly affect houses with many bedrooms.\n",
    "* bedrooms times bathrooms gives what's called an \"interaction\" feature. It is large when *both* of them are large.\n",
    "* Taking the log of squarefeet has the effect of bringing large values closer together and spreading out small values.\n",
    "* Adding latitude to longitude is totally non-sensical but we will do it anyway (you'll see why)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the mean (arithmetic average) value of your 4 new features on TEST data? (round to 2 digits)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-74.65333497217306"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['lat_plus_long'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will learn the weights for three (nested) models for predicting house prices. The first model will have the fewest features the second model will add one more feature and the third will add a few more:\n",
    "* Model 1: squarefeet, # bedrooms, # bathrooms, latitude & longitude\n",
    "* Model 2: add bedrooms\\*bathrooms\n",
    "* Model 3: Add log squarefeet, bedrooms squared, and the (nonsensical) latitude + longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1_features = ['sqft_living', 'bedrooms', 'bathrooms', 'lat', 'long']\n",
    "model_2_features = model_1_features + ['bed_bath_rooms']\n",
    "model_3_features = model_2_features + ['bedrooms_squared', 'log_sqft_living', 'lat_plus_long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the features, learn the weights for the three different models for predicting target = 'price' using graphlab.linear_regression.create() and look at the value of the weights/coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 17384\n",
      "PROGRESS: Number of features          : 5\n",
      "PROGRESS: Number of unpacked features : 5\n",
      "PROGRESS: Number of coefficients    : 6\n",
      "PROGRESS: Starting Newton Method\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 2        | 0.068740     | 4074878.213096     | 236378.596455 |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: SUCCESS: Optimal solution found.\n",
      "PROGRESS:\n",
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 17384\n",
      "PROGRESS: Number of features          : 6\n",
      "PROGRESS: Number of unpacked features : 6\n",
      "PROGRESS: Number of coefficients    : 7\n",
      "PROGRESS: Starting Newton Method\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 2        | 0.072958     | 4014170.932927     | 235190.935428 |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: SUCCESS: Optimal solution found.\n",
      "PROGRESS:\n",
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 17384\n",
      "PROGRESS: Number of features          : 9\n",
      "PROGRESS: Number of unpacked features : 9\n",
      "PROGRESS: Number of coefficients    : 10\n",
      "PROGRESS: Starting Newton Method\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | 1         | 2        | 0.045361     | 3193229.177894     | 228200.043155 |\n",
      "PROGRESS: +-----------+----------+--------------+--------------------+---------------+\n",
      "PROGRESS: SUCCESS: Optimal solution found.\n",
      "PROGRESS:\n"
     ]
    }
   ],
   "source": [
    "# Learn the three models: (don't forget to set validation_set = None)\n",
    "model_1 = graphlab.linear_regression.create(train_data, target = 'price', features = model_1_features, \n",
    "                                                  validation_set = None)\n",
    "model_2 = graphlab.linear_regression.create(train_data, target = 'price', features = model_2_features,\n",
    "                                                  validation_set = None)\n",
    "model_3 = graphlab.linear_regression.create(train_data, target = 'price', features = model_3_features,\n",
    "                                                  validation_set = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+----------------+\n",
      "|     name    | index |     value      |\n",
      "+-------------+-------+----------------+\n",
      "| (intercept) |  None | -56140675.7444 |\n",
      "| sqft_living |  None | 310.263325778  |\n",
      "|   bedrooms  |  None | -59577.1160682 |\n",
      "|  bathrooms  |  None | 13811.8405418  |\n",
      "|     lat     |  None | 629865.789485  |\n",
      "|     long    |  None | -214790.285186 |\n",
      "+-------------+-------+----------------+\n",
      "[6 rows x 3 columns]\n",
      "\n",
      "+----------------+-------+----------------+\n",
      "|      name      | index |     value      |\n",
      "+----------------+-------+----------------+\n",
      "|  (intercept)   |  None | -54410676.1152 |\n",
      "|  sqft_living   |  None | 304.449298057  |\n",
      "|    bedrooms    |  None | -116366.043231 |\n",
      "|   bathrooms    |  None | -77972.3305135 |\n",
      "|      lat       |  None | 625433.834953  |\n",
      "|      long      |  None | -203958.60296  |\n",
      "| bed_bath_rooms |  None | 26961.6249092  |\n",
      "+----------------+-------+----------------+\n",
      "[7 rows x 3 columns]\n",
      "\n",
      "+------------------+-------+----------------+\n",
      "|       name       | index |     value      |\n",
      "+------------------+-------+----------------+\n",
      "|   (intercept)    |  None | -52974974.0602 |\n",
      "|   sqft_living    |  None | 529.196420564  |\n",
      "|     bedrooms     |  None | 28948.5277313  |\n",
      "|    bathrooms     |  None |  65661.207231  |\n",
      "|       lat        |  None | 704762.148408  |\n",
      "|       long       |  None | -137780.01994  |\n",
      "|  bed_bath_rooms  |  None | -8478.36410518 |\n",
      "| bedrooms_squared |  None | -6072.38466067 |\n",
      "| log_sqft_living  |  None | -563467.784269 |\n",
      "|  lat_plus_long   |  None | -83217.1979248 |\n",
      "+------------------+-------+----------------+\n",
      "[10 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine/extract each model's coefficients:\n",
    "print model_1.get(\"coefficients\")\n",
    "print model_2.get(\"coefficients\")\n",
    "print model_3.get(\"coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the sign (positive or negative) for the coefficient/weight for 'bathrooms' in model 1?**\n",
    "\n",
    "**Quiz Question: What is the sign (positive or negative) for the coefficient/weight for 'bathrooms' in model 2?**\n",
    "\n",
    "Think about what this means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing multiple models\n",
    "\n",
    "Now that you've learned three models and extracted the model weights we want to evaluate which model is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use your functions from earlier to compute the RSS on TRAINING Data for each of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.71328233544e+14 9.61592067856e+14 9.05276314555e+14\n"
     ]
    }
   ],
   "source": [
    "# Compute the RSS on TRAINING data for each of the three models and record the values:\n",
    "rss_model_1 = get_residual_sum_of_squares(model_1, train_data, train_data['price'])\n",
    "rss_model_2 = get_residual_sum_of_squares(model_2, train_data, train_data['price'])\n",
    "rss_model_3 = get_residual_sum_of_squares(model_3, train_data, train_data['price'])\n",
    "print rss_model_1, rss_model_2, rss_model_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which model (1, 2 or 3) has lowest RSS on TRAINING Data?** Is this what you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the RSS on on TEST data for each of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.26568089093e+14 2.24368799994e+14 2.51829318952e+14\n"
     ]
    }
   ],
   "source": [
    "# Compute the RSS on TESTING data for each of the three models and record the values:\n",
    "rss_model_1 = get_residual_sum_of_squares(model_1, test_data, test_data['price'])\n",
    "rss_model_2 = get_residual_sum_of_squares(model_2, test_data, test_data['price'])\n",
    "rss_model_3 = get_residual_sum_of_squares(model_3, test_data, test_data['price'])\n",
    "print rss_model_1, rss_model_2, rss_model_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which model (1, 2 or 3) has lowest RSS on TESTING Data?** Is this what you expected?Think about the features that were added to each model from the previous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # add a constant column to an SFrame\n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "    # select the columns of data_SFrame given by the ‘features’ list into the SFrame ‘features_sframe’\n",
    "    features_sframe = data_sframe.select_columns(features)\n",
    "    # this will convert the features_sframe into a numpy matrix with GraphLab Create >= 1.7!!\n",
    "    features_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the target to the variable ‘output_sarray’\n",
    "    output_sarray = data_sframe.select_column(output)\n",
    "    # this will convert the SArray into a numpy array:\n",
    "    output_array = output_sarray.to_numpy() # GraphLab Create>= 1.7!!\n",
    "    return(features_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_outcome(feature_matrix, weights):\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    derivative = 2 * np.dot(errors, feature)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False\n",
    "    weights = np.array(initial_weights)\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights:\n",
    "        predictions = predict_outcome(feature_matrix, weights)\n",
    "        # compute the errors as predictions - output:\n",
    "        errors = predictions - output\n",
    "        gradient_sum_squares = 0 # initialize the gradient\n",
    "        # while not converged, update each weight individually:\n",
    "        for i in range(len(weights)):\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:, i])\n",
    "            # add the squared derivative to the gradient magnitude\n",
    "            gradient_sum_squares = gradient_sum_squares + derivative * derivative\n",
    "            # update the weight based on step size and derivative:\n",
    "            weights[i] = weights[i] - step_size * derivative\n",
    "        gradient_magnitude = np.sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output= 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_weights = regression_gradient_descent(simple_feature_matrix, output,initial_weights, step_size,tolerance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_simple_weights = regression_gradient_descent(test_simple_feature_matrix, test_output,initial_weights, step_size,tolerance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_predict = np.dot(test_simple_feature_matrix, test_simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15']\n",
    "my_output= 'price'\n",
    "(model_feature_matrix, model_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "model_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_model_weights = regression_gradient_descent(model_feature_matrix, model_output, model_weights, step_size,tolerance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_predict = np.dot(model_feature_matrix, new_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 356134.44317093,  784640.86422788,  435069.83652353, ...,\n",
       "        663418.65300782,  604217.10799338,  240550.4743332 ])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 310000.,  650000.,  233000., ...,  610685.,  400000.,  402101.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_error = simple_predict - test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16595181.45707229"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((simple_error * simple_error).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_error = model_predict - model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16427745.400005188"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((model_error * model_error).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476224.60440095473"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.dot(model_2_matrix[0, 0:7], model_2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 376094.1267137 ,  754494.14824362,  377778.93547329, ...,\n",
       "        687596.82507458,  581967.20574374,  218789.22834502])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-46999.88120687,    282.34308957])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_simple_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_predict = np.dot(test_simple_feature_matrix, test_simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 356774.1395186 ,  785960.50864093,  435834.78646219, ...,\n",
       "        664545.94369185,  605250.45848416,  241006.76363692])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 376094.1267137 ,  754494.14824362,  377778.93547329, ...,\n",
       "        687596.82507458,  581967.20574374,  218789.22834502])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output= 'price'\n",
    "(test_simple_feature_matrix, test_output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_simple_weights = regression_gradient_descent(test_simple_feature_matrix, test_output,initial_weights, step_size,tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15']\n",
    "my_output= 'price'\n",
    "(model_feature_matrix, model_output) = get_numpy_data(train_data, model_features, my_output)\n",
    "model_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_model_weights = regression_gradient_descent(model_feature_matrix, model_output, model_weights, step_size,tolerance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 356134.44317093,  784640.86422788,  435069.83652353, ...,\n",
       "        663418.65300782,  604217.10799338,  240550.4743332 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(test_simple_feature_matrix, simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 376094.1267137 ,  754494.14824362,  377778.93547329, ...,\n",
       "        687596.82507458,  581967.20574374,  218789.22834502])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(model_feature_matrix, new_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-46999.87880043,    282.35945337])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_simple_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   1.43000000e+03],\n",
       "       [  1.00000000e+00,   2.95000000e+03],\n",
       "       [  1.00000000e+00,   1.71000000e+03],\n",
       "       ..., \n",
       "       [  1.00000000e+00,   2.52000000e+03],\n",
       "       [  1.00000000e+00,   2.31000000e+03],\n",
       "       [  1.00000000e+00,   1.02000000e+03]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_simple_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356774.13951867"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.43000000e+03 * 282.35945337 -46999.87880043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15']\n",
    "my_output= 'price'\n",
    "(test_model_feature_matrix, test_model_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "model_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 366651.41203656,  762662.39786164,  386312.09499712, ...,\n",
       "        682087.39928241,  585579.27865729,  216559.20396617])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(test_model_feature_matrix, new_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
